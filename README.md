## Projeto: ClassificaÃ§Ã£o â€” Ãrvore de DecisÃ£o

Este repositÃ³rio contÃ©m um projeto prÃ¡tico de classificaÃ§Ã£o baseado em Ã¡rvore de decisÃ£o. O objetivo deste README Ã© documentar de forma clara e didÃ¡tica tudo o que vocÃª jÃ¡ fez aqui, como reproduzir os resultados, o que estudar para entender cada etapa e prÃ³ximos passos recomendados â€” tudo alinhado ao mÃ³dulo "ClassificaÃ§Ã£o Ãrvore de DecisÃ£o" da formaÃ§Ã£o "Machine Learning em InteligÃªncia Artificial" da Rocketseat.

### ConteÃºdo deste repositÃ³rio

- `classificacao_segment_empresa.ipynb` â€” notebook com o fluxo principal: EDA, prÃ©-processamento, treinamento e avaliaÃ§Ã£o do modelo.
- `modelo_classficacao_decision_tree.pkl` â€” modelo treinado (Decision Tree) serializado (pickle) para inferÃªncia em batch.
- `predicoes.csv` â€” exemplo de saÃ­da de prediÃ§Ãµes (arquivo gerado apÃ³s inferÃªncia).
- `Pipfile` / `Pipfile.lock` â€” gerenciador de dependÃªncias (Pipenv).
- `datasets/novas_empresas.csv` â€” dados de entrada para inferÃªncia (novas amostras).
- `datasets/segmento_clientes.csv` â€” dataset original / base utilizada no projeto (ou similar) para treinamento e anÃ¡lise.

Se algum arquivo nÃ£o estiver presente ou tiver outro nome, verifique o notebook `classificacao_segment_empresa.ipynb` para referÃªncias exatas.

## Resumo do fluxo realizado

1. Coleta / carregamento dos dados (`segmento_clientes.csv`).
2. AnÃ¡lise ExploratÃ³ria de Dados (EDA): inspeÃ§Ã£o de colunas, tipos, valores ausentes, distribuiÃ§Ã£o de classes e visualizaÃ§Ãµes (histogramas, boxplots, tabelas de frequÃªncia).
3. Limpeza e prÃ©-processamento: tratamento de valores ausentes, codificaÃ§Ã£o de variÃ¡veis categÃ³ricas (LabelEncoder / OneHotEncoding conforme necessidade), normalizaÃ§Ã£o/scale quando aplicÃ¡vel.
4. Engenharia de features: criaÃ§Ã£o/seleÃ§Ã£o de colunas relevantes com base em EDA.
5. SeparaÃ§Ã£o treino / teste (train_test_split) e definiÃ§Ã£o de seed para reprodutibilidade.
6. Treinamento de um DecisionTreeClassifier (sklearn): escolha de critÃ©rios (gini/entropy), controle de profundidade e parÃ¢metros de regularizaÃ§Ã£o.
7. AvaliaÃ§Ã£o do modelo: acurÃ¡cia, matriz de confusÃ£o, classification report (precision/recall/f1), e anÃ¡lise de overfitting/underfitting.
8. PersistÃªncia do modelo (`pickle`) em `modelo_classficacao_decision_tree.pkl`.
9. InferÃªncia em batch usando `datasets/novas_empresas.csv` gerando `predicoes.csv`.

## Como reproduzir o ambiente e rodar o projeto

Recomendado: use Pipenv (hÃ¡ um `Pipfile` no repositÃ³rio). No Windows (PowerShell), execute:

```powershell
pipenv install --dev
pipenv shell
pipenv run jupyter notebook
```

Abra `classificacao_segment_empresa.ipynb` e execute as cÃ©lulas em ordem. Se preferir executar apenas inferÃªncia a partir do modelo salvo, crie um script Python simples (exemplo abaixo).

Exemplo mÃ­nimo para carregar o modelo e gerar prediÃ§Ãµes (arquivo `inferencia_batch.py` â€” opÃ§Ã£o):

```python
import pandas as pd
import pickle

# carregar dados
df = pd.read_csv('datasets/novas_empresas.csv')

# prÃ©-processamento idÃªntico ao usado no notebook (importante!)
# ...aplicar transformaÃ§Ãµes: encoding, criaÃ§Ã£o de features, seleÃ§Ã£o de colunas...

# carregar modelo
with open('modelo_classficacao_decision_tree.pkl', 'rb') as f:
    model = pickle.load(f)

# previsÃµes
preds = model.predict(df)
df['predicao'] = preds
df.to_csv('predicoes.csv', index=False)


# ğŸ“Š Projeto: ClassificaÃ§Ã£o â€” Ãrvore de DecisÃ£o (Decision Tree)

## ğŸ“š Sobre o projeto

Este repositÃ³rio implementa um modelo de classificaÃ§Ã£o usando Ãrvore de DecisÃ£o (sklearn). Ã‰ um projeto prÃ¡tico alinhado ao mÃ³dulo "ClassificaÃ§Ã£o â€” Ãrvore de DecisÃ£o" da formaÃ§Ã£o "Machine Learning em InteligÃªncia Artificial" (Rocketseat). O objetivo Ã© mostrar todo o fluxo: EDA, prÃ©-processamento, treino, avaliaÃ§Ã£o, persistÃªncia do modelo e inferÃªncia em batch.

### ğŸ¯ Problema a ser resolvido

â€¢ VariÃ¡veis de entrada: atributos das empresas (dados em `datasets/segmento_clientes.csv`)
â€¢ VariÃ¡vel alvo (y): segmento/label de classificaÃ§Ã£o (ver notebook para o nome exato da coluna)
â€¢ Objetivo: treinar um modelo que classifique corretamente o segmento de uma empresa com base nas suas features.

## ğŸ› ï¸ Tecnologias utilizadas

â€¢ Python 3.11+
â€¢ Pandas, NumPy â€” manipulaÃ§Ã£o de dados
â€¢ Scikit-learn â€” DecisionTreeClassifier, mÃ©tricas e utilitÃ¡rios
â€¢ Matplotlib/Seaborn â€” visualizaÃ§Ã£o (usado no notebook)
â€¢ Pipenv â€” gerenciamento de dependÃªncias (Pipfile presente)

> ObservaÃ§Ã£o: se vocÃª quiser uma API/serviÃ§o, podemos adicionar FastAPI e Uvicorn (opcional).

## ğŸ“ Estrutura do projeto

```

ml-decision-tree-classification/
â”œâ”€â”€ datasets/
â”‚ â”œâ”€â”€ segmento_clientes.csv # dataset usado para treino/EDA
â”‚ â””â”€â”€ novas_empresas.csv # amostras para inferÃªncia em batch
â”œâ”€â”€ classificacao_segment_empresa.ipynb # notebook: EDA â†’ treino â†’ avaliaÃ§Ã£o
â”œâ”€â”€ modelo_classficacao_decision_tree.pkl # modelo treinado serializado
â”œâ”€â”€ predicoes.csv # exemplo de saÃ­da gerada em inferÃªncia
â”œâ”€â”€ Pipfile
â”œâ”€â”€ Pipfile.lock
â””â”€â”€ README.md

```

## ğŸ§  Conceitos de Machine Learning aplicados

â€¢ ClassificaÃ§Ã£o: Ã¡rvore de decisÃ£o â€” splits baseados em Gini/Entropy
â€¢ ValidaÃ§Ã£o: holdout (train/test) e possibilidade de k-fold estratificado
â€¢ MÃ©tricas: acurÃ¡cia, precision, recall, f1-score, matriz de confusÃ£o
â€¢ Overfitting vs Underfitting: controle por `max_depth`, `min_samples_leaf`, etc.

## ğŸ“ˆ Processo de Machine Learning implementado

1. Carregamento dos dados e EDA (inspeÃ§Ã£o, estatÃ­sticas, grÃ¡ficos)
2. Tratamento de valores faltantes e codificaÃ§Ã£o de categÃ³ricas
3. SeparaÃ§Ã£o treino/teste (com `random_state` fixo)
4. Treinamento de `DecisionTreeClassifier`
5. AvaliaÃ§Ã£o com mÃ©tricas e matriz de confusÃ£o
6. Salvamento do modelo (`pickle`) em `modelo_classficacao_decision_tree.pkl`
7. InferÃªncia em batch em `datasets/novas_empresas.csv` â†’ `predicoes.csv`

## ğŸ“Š Dataset

Arquivo principal: `datasets/segmento_clientes.csv` â€” abra o notebook para ver as colunas e amostras. Se precisar, adicione uma amostra mÃ­nima abaixo para referÃªncia.

Exemplo de visualizaÃ§Ã£o (no notebook):
```

... mostra as primeiras linhas com .head() ...

````

## ğŸš€ Como executar o projeto

1. Instalar Pipenv (se nÃ£o tiver):

```powershell
pip install pipenv
````

2. Instalar dependÃªncias e abrir ambiente (PowerShell):

```powershell
pipenv install --dev
pipenv shell
```

3. Rodar Jupyter Notebook e abrir o notebook de anÃ¡lise:

```powershell
jupyter notebook classificacao_segment_empresa.ipynb
```

### InferÃªncia rÃ¡pida a partir do modelo salvo

Se quiser apenas gerar prediÃ§Ãµes no arquivo `datasets/novas_empresas.csv`, crie um script `inferencia_batch.py` (exemplo abaixo) e execute dentro do mesmo ambiente:

```python
import pandas as pd
import pickle

# carregar dados
df = pd.read_csv('datasets/novas_empresas.csv')

# ATENÃ‡ÃƒO: aplicar as mesmas transformaÃ§Ãµes usadas no treinamento
# Exemplo mÃ­nimo: selecionar colunas esperadas pelo modelo
# df = df[ ['col1','col2', ...] ]

with open('modelo_classficacao_decision_tree.pkl','rb') as f:
    model = pickle.load(f)

preds = model.predict(df)
df['predicao'] = preds
df.to_csv('predicoes.csv', index=False)
print('Arquivo gerado: predicoes.csv')
```

## ğŸ” API / Deploy (opcional)

No momento este repositÃ³rio nÃ£o inclui uma API pronta. Se quiser, eu posso adicionar um pequeno `api_modelo.py` com FastAPI e um `api_main.py` (similar ao padrÃ£o do seu outro repo), que:

- carrega o modelo serializado
- expÃµe um endpoint POST `/predict` que recebe JSON com uma amostra e retorna a prediÃ§Ã£o

### Exemplos de uso da API (apÃ³s adicionar FastAPI):

- `uvicorn api_modelo:app --reload --port 8000`
- DocumentaÃ§Ã£o automÃ¡tica: `http://localhost:8000/docs`

## ğŸ“ Material de estudo recomendado (Rocketseat)

- MÃ³dulo: ClassificaÃ§Ã£o â€” Ãrvore de DecisÃ£o (Rocketseat): https://app.rocketseat.com.br/classroom/classificacao-arvore-de-decisao
- Scikit-Learn â€” Decision Trees: https://scikit-learn.org/stable/modules/tree.html
- Conceitos: Entropia, Gini, Overfitting/Pruning, ValidaÃ§Ã£o cruzada, Feature importance

## âœ… Resumo para estudo rÃ¡pido

O que foi implementado:

- Modelo Decision Tree treinado e salvo
- Notebook com EDA e avaliaÃ§Ã£o
- Exemplo de inferÃªncia em batch (arquivo `predicoes.csv`)

Como testar rapidamente:

1. `pipenv install --dev`
2. `pipenv shell`
3. `jupyter notebook classificacao_segment_empresa.ipynb` ou executar `inferencia_batch.py` para gerar `predicoes.csv`

## ğŸ¤ Como contribuir

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nome-da-feature`)
3. Commit e push
4. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto pode usar a licenÃ§a MIT. Se quiser, adiciono o arquivo `LICENSE`.

---

Se quiser, posso agora:

- gerar o script `inferencia_batch.py` automaticamente com base no prÃ©-processamento do notebook;
- gerar um `requirements.txt` a partir do `Pipfile`;
- adicionar `api_modelo.py` + `api_main.py` com FastAPI seguindo o padrÃ£o do seu repo de regressÃ£o.

Diga qual aÃ§Ã£o prefere que eu faÃ§a a seguir e eu implemento.
